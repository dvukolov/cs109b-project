{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscelaneous helper functions for Xception CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.python.util import nest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapt_model(model, dataset):\n",
    "    \"\"\"Adapt the preprocessing layers, e.g. Normalization(), to the dataset.\n",
    "    \"\"\"\n",
    "    if isinstance(dataset, tf.data.Dataset):\n",
    "        x = dataset.map(lambda x, y: x)\n",
    "    else:\n",
    "        x = nest.flatten(dataset)\n",
    "\n",
    "    def get_output_layer(tensor):\n",
    "        tensor = nest.flatten(tensor)[0]\n",
    "        for layer in model.layers:\n",
    "            if isinstance(layer, tf.keras.layers.InputLayer):\n",
    "                continue\n",
    "            input_node = nest.flatten(layer.input)[0]\n",
    "            if input_node is tensor:\n",
    "                return layer\n",
    "        return None\n",
    "\n",
    "    for index, input_node in enumerate(nest.flatten(model.input)):\n",
    "\n",
    "        def get_data(*args):\n",
    "            return args[index]\n",
    "\n",
    "        if isinstance(x, tf.data.Dataset):\n",
    "            temp_x = x.map(get_data)\n",
    "        else:\n",
    "            temp_x = x[index]\n",
    "        layer = get_output_layer(input_node)\n",
    "        while isinstance(layer, preprocessing.PreprocessingLayer):\n",
    "            layer.adapt(temp_x)\n",
    "            layer = get_output_layer(layer.output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define available models\n",
    "xception_models = [\n",
    "    {\n",
    "        \"name\": \"Noiseless images with fixed PSF\",\n",
    "        \"X\": lambda data: data[\"img_nonoise\"][..., np.newaxis],\n",
    "        \"dataset\": \"../data/data_v1.npz\",\n",
    "        \"modelpath\": \"../models/xception_data_v1_noiseless.tf\",\n",
    "        \"scalerpath\": \"../models/xception_data_v1.scaler\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Noisy images with fixed PSF and noise\",\n",
    "        \"X\": lambda data: data[\"img\"][..., np.newaxis],\n",
    "        \"dataset\": \"../data/data_v1.npz\",\n",
    "        \"modelpath\": \"../models/xception_data_v1.tf\",\n",
    "        \"scalerpath\": \"../models/xception_data_v1.scaler\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Noisy images with fixed PSF and varying noise\",\n",
    "        \"X\": lambda data: data[\"img\"][..., np.newaxis],\n",
    "        \"dataset\": \"../data/data_v2.npz\",\n",
    "        \"modelpath\": \"../models/xception_data_v2.tf\",\n",
    "        \"scalerpath\": \"../models/xception_data_v2.scaler\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Noisy images with varying PSF and noise\",\n",
    "        \"X\": lambda data: np.stack((data[\"img\"], data[\"psf_img\"]), axis=-1),\n",
    "        \"dataset\": \"../data/data_v3.npz\",\n",
    "        \"modelpath\": \"../models/xception_data_v3.tf\",\n",
    "        \"scalerpath\": \"../models/xception_data_v3.scaler\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_xception_model(model_version):\n",
    "    \"\"\"Load a model that was trained on a particular dataset.\n",
    "    \"\"\"\n",
    "    config = xception_models[model_version]\n",
    "    with open(config[\"scalerpath\"], \"rb\") as f:\n",
    "        scaler = pickle.load(f)\n",
    "\n",
    "    model = tf.keras.models.load_model(config[\"modelpath\"])\n",
    "\n",
    "    return model, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_xception(model_version):\n",
    "    \"\"\"Load a model and the corresponding dataset.\n",
    "\n",
    "    Args:\n",
    "        model_version: an identificator of the model\n",
    "    Returns:\n",
    "        a dictionary with a model, a scaler, X, y, ...\n",
    "    \"\"\"\n",
    "    config = xception_models[model_version]\n",
    "    model, scaler = load_xception_model(model_version)\n",
    "\n",
    "    with np.load(config[\"dataset\"]) as data:\n",
    "        X = config[\"X\"](data)\n",
    "        label = data[\"label\"]\n",
    "        snr = data[\"snr\"]\n",
    "        noisy = data[\"img\"]\n",
    "        noiseless = data[\"img_nonoise\"]\n",
    "        psf_r = data[\"psf_r\"]\n",
    "        sigma = data[\"sigma\"]\n",
    "\n",
    "    # Obtain the validation set\n",
    "    n_train = int(label.shape[0] * 0.9)\n",
    "    X_val = X[n_train:]\n",
    "    y_val = label[n_train:]\n",
    "    snr_val = snr[n_train:]\n",
    "    noisy_val = noisy[n_train:]\n",
    "    noiseless_val = noiseless[n_train:]\n",
    "    psf_r_val = psf_r[n_train:]\n",
    "    sigma_val = sigma[n_train:]\n",
    "\n",
    "    result = {\n",
    "        \"model\": model,\n",
    "        \"scaler\": scaler,\n",
    "        \"X\": X,\n",
    "        \"y\": label,\n",
    "        \"snr\": snr,\n",
    "        \"X_val\": X_val,\n",
    "        \"y_val\": y_val,\n",
    "        \"snr_val\": snr_val,\n",
    "        \"noisy_val\": noisy_val,\n",
    "        \"noiseless_val\": noiseless_val,\n",
    "        \"psf_r_val\": psf_r_val,\n",
    "        \"sigma_val\": sigma_val,\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_experiments():\n",
    "    \"\"\"Load a set of experiments for training the models.\n",
    "    \"\"\"\n",
    "    for experiment in xception_models:\n",
    "        with np.load(experiment[\"dataset\"]) as data:\n",
    "            X = experiment[\"X\"](data)\n",
    "            label = data[\"label\"]\n",
    "\n",
    "        experiment = experiment.copy()\n",
    "        experiment[\"X\"] = X\n",
    "        experiment[\"label\"] = label\n",
    "        yield experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_testset(snr, load_psf=False):\n",
    "    datasets = {30: \"../data/snr30.npz\", 60: \"../data/snr60.npz\"}\n",
    "\n",
    "    dataset = datasets[snr]\n",
    "    with np.load(dataset) as data:\n",
    "        image = data[\"img\"]\n",
    "        psf_image = data[\"psf_img\"]\n",
    "        label = data[\"label\"]\n",
    "\n",
    "    if load_psf:\n",
    "        X = np.stack((image, np.broadcast_to(psf_image, image.shape)), axis=-1)\n",
    "    else:\n",
    "        X = image[..., np.newaxis]\n",
    "\n",
    "    # All labels in the test set are the same, take the first one\n",
    "    y = label[0]\n",
    "\n",
    "    return X, y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
