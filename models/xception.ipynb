{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Xception CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.applications import xception\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.python.util import nest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_xception_model(\n",
    "    input_shape,\n",
    "    output_shape,\n",
    "    normalize=True,\n",
    "    conv2d_num_filters=64,\n",
    "    kernel_size=5,\n",
    "    initial_strides=2,\n",
    "    activation=\"selu\",\n",
    "    sep_num_filters=256,\n",
    "    num_residual_blocks=4,\n",
    "    pooling=\"avg\",\n",
    "    dropout_rate=0,\n",
    "):\n",
    "    \"\"\"Build an image regression model with Xception blocks.\n",
    "    Original architecture by FranÃ§ois Chollet https://arxiv.org/pdf/1610.02357.pdf\n",
    "    Code based on Autokeras and Keras Tuner.\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(input_shape) == 3, \"The input images should have a channel dimension\"\n",
    "    assert activation in [\"relu\", \"selu\"]\n",
    "    assert pooling in [\"avg\", \"flatten\", \"max\"]\n",
    "\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "\n",
    "    if normalize:\n",
    "        # Compute the mean and the variance of the dataset and store it as model weights.\n",
    "        # Don't forget to use adapt_model(model, X) before fitting the model.\n",
    "        x = preprocessing.Normalization()(x)\n",
    "\n",
    "    # Initial conv2d\n",
    "    x = xception.conv(\n",
    "        x, conv2d_num_filters, kernel_size=kernel_size, activation=activation, strides=initial_strides\n",
    "    )\n",
    "\n",
    "    # Separable convolutions\n",
    "    for _ in range(num_residual_blocks):\n",
    "        x = xception.residual(x, sep_num_filters, activation=activation, max_pooling=False)\n",
    "\n",
    "    # Exit flow\n",
    "    x = xception.residual(x, 2 * sep_num_filters, activation=activation, max_pooling=True)\n",
    "\n",
    "    pooling_layers = {\n",
    "        \"flatten\": layers.Flatten,\n",
    "        \"avg\": layers.GlobalAveragePooling2D,\n",
    "        \"max\": layers.GlobalMaxPooling2D,\n",
    "    }\n",
    "    x = pooling_layers[pooling]()(x)\n",
    "\n",
    "    # Regression head\n",
    "    if dropout_rate > 0:\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    outputs = layers.Dense(output_shape[-1])(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapt_model(model, dataset):\n",
    "    \"\"\"Adapt the preprocessing layers, e.g. Normalization(), to the dataset.\n",
    "    \"\"\"\n",
    "    if isinstance(dataset, tf.data.Dataset):\n",
    "        x = dataset.map(lambda x, y: x)\n",
    "    else:\n",
    "        x = nest.flatten(dataset)\n",
    "    \n",
    "    def get_output_layer(tensor):\n",
    "        tensor = nest.flatten(tensor)[0]\n",
    "        for layer in model.layers:\n",
    "            if isinstance(layer, tf.keras.layers.InputLayer):\n",
    "                continue\n",
    "            input_node = nest.flatten(layer.input)[0]\n",
    "            if input_node is tensor:\n",
    "                return layer\n",
    "        return None\n",
    "\n",
    "    for index, input_node in enumerate(nest.flatten(model.input)):\n",
    "        def get_data(*args):\n",
    "            return args[index]\n",
    "\n",
    "        if isinstance(x, tf.data.Dataset):\n",
    "            temp_x = x.map(get_data)\n",
    "        else:\n",
    "            temp_x = x[index]\n",
    "        layer = get_output_layer(input_node)\n",
    "        while isinstance(layer, preprocessing.PreprocessingLayer):\n",
    "            layer.adapt(temp_x)\n",
    "            layer = get_output_layer(layer.output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Usage examples:\n",
    "# model = build_xception_model(input_shape=(64, 64, 1), output_shape=(5,), num_residual_blocks=7)\n",
    "# model.summary()\n",
    "\n",
    "# # Adapt the normalization layer to the data\n",
    "# adapt_model(model, data)\n",
    "# model.fit(...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
