{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autokeras as ak\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "%run utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_padding(kernel_size, output_node):\n",
    "    if all([kernel_size * 2 <= length\n",
    "            for length in output_node.shape[1:-1]]):\n",
    "        return 'valid'\n",
    "    return 'same'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(\n",
    "    input_shape,\n",
    "    output_shape,\n",
    "    normalize=True,\n",
    "    kernel_size=3,\n",
    "    num_blocks=2,\n",
    "    num_layers=2,\n",
    "    filters=(32, 32, 32, 32),\n",
    "    separable=False,\n",
    "    max_pooling=True,\n",
    "    dropout_rate=0,\n",
    "    batchnorm=False,\n",
    "):\n",
    "    \"\"\"Build an vanilla CNN regression model with option optional separable blocks.\n",
    "    Code based on Autokeras.\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(input_shape) == 3, \"The input images should have a channel dimension\"\n",
    "    assert len(filters) == num_blocks * num_layers\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "\n",
    "    if normalize:\n",
    "        # Compute the mean and the variance of the dataset and store it as model weights.\n",
    "        # Don't forget to use adapt_model(model, X) before fitting the model.\n",
    "        x = preprocessing.Normalization()(x)\n",
    "\n",
    "    if separable:\n",
    "        conv = ak.utils.get_sep_conv(inputs.shape)\n",
    "    else:\n",
    "        conv = ak.utils.get_conv(inputs.shape)\n",
    "\n",
    "    pool = ak.utils.get_max_pooling(inputs.shape)\n",
    "\n",
    "    counter = 0\n",
    "    for i in range(num_blocks):\n",
    "        for j in range(num_layers):\n",
    "            x = conv(filters[counter], kernel_size,\n",
    "                               padding=_get_padding(kernel_size, x),\n",
    "                               activation='relu')(x)\n",
    "            counter += 1\n",
    "        if max_pooling:\n",
    "            x = pool(kernel_size - 1,\n",
    "                               padding=_get_padding(kernel_size - 1, x))(x)\n",
    "        if dropout_rate > 0:\n",
    "            x = layers.Dropout(dropout_rate)(x)\n",
    "        \n",
    "        if batchnorm:\n",
    "            x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Regression head\n",
    "    x = layers.Flatten()(x)\n",
    "    outputs = layers.Dense(output_shape[-1])(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example:\n",
    "# model = build_cnn_model(input_shape=(64, 64, 1), output_shape=(5,), num_blocks=3, separable=True,\n",
    "#                        filters=(16, 16, 16, 512, 512, 16), batchnorm=True)\n",
    "# adapt_model(model, X)\n",
    "# model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
